{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSO560 Hugging Face Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lswOTHDPU270"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq_nZRCadmZ4"
      },
      "source": [
        "# Welcome to our Huggingface Demo!\n",
        "\n",
        "- This notebook gives some ideas about how we can use Huggingface's transformers library to do some VERY COOL STUFF with VERY LITTLE CODE\n",
        "- Examples are drawn from Huggingface github here: https://github.com/huggingface/notebooks/blob/master/transformers_doc/task_summary.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrISJp0jmAvg"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCqz5pPAUwmD"
      },
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k3_zLS7U1bX"
      },
      "source": [
        "demo_text = \"Yu Chen is the best teacher ever\"\n",
        "classifier(demo_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5z5e9WsVRRk"
      },
      "source": [
        "demo_text = \"Yu Chen is not the best teacher ever\"\n",
        "classifier(demo_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAwdEFFzVURk"
      },
      "source": [
        "demo_text = \"Yu Chen is not not the best teacher ever\"\n",
        "classifier(demo_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An_d0k_YmSbA"
      },
      "source": [
        "# Sentiment Analysis - Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZlFDkg5VYQo"
      },
      "source": [
        "review_text = \"I did not hate anything about this movie!\"\n",
        "classifier(review_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APb-QlMbm6Hk"
      },
      "source": [
        "review_text = \"I did not like one thing about this product!\"\n",
        "classifier(review_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnWtdjcwo7ko"
      },
      "source": [
        "# Paraphrasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fUSDcSNo6hq"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO-Ozzfvm-2k"
      },
      "source": [
        "## PYTORCH CODE\n",
        "sequence_0 = \"This is a natural language processing class at Marshall Business School\"\n",
        "sequence_1 = \"USC has great deep learning classes\"\n",
        "sequence_2 = \"Marshall offers a language processing course\"\n",
        "# The tokenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to\n",
        "# the sequence, as well as compute the attention masks.\n",
        "\n",
        "print('full statement:', sequence_0)\n",
        "\n",
        "paraphrase = tokenizer(sequence_0, sequence_1, return_tensors=\"pt\")\n",
        "paraphrase_classification_logits = model(**paraphrase).logits\n",
        "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
        "\n",
        "\n",
        "print('\\nprobability \"', sequence_1, '\" is paraphrase:', paraphrase_results[1])\n",
        "\n",
        "paraphrase = tokenizer(sequence_0, sequence_2, return_tensors=\"pt\")\n",
        "paraphrase_classification_logits = model(**paraphrase).logits\n",
        "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
        "\n",
        "print('\\nprobability \"', sequence_2, '\" is paraphrase:', paraphrase_results[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1yuZU9Ep96-"
      },
      "source": [
        "# Extractive Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcyyQ8-pqP2R"
      },
      "source": [
        "from transformers import pipeline\n",
        "question_answerer = pipeline(\"question-answering\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgBO64roTZd"
      },
      "source": [
        "context = r\"\"\"\n",
        "Telsa stock soared today after another positive earnings report.  \n",
        "Elon Musk did some silly stuff on one of his friend's podcasts, but that only seemed to help.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyqJCOfJqPLG"
      },
      "source": [
        "result = question_answerer(question=\"What did Elon Musk do?\", context=context)\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hktXnyQRqimc"
      },
      "source": [
        "result = question_answerer(question=\"What happened to Tesla's stock today?\", context=context)\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D38PmOt_q-WY"
      },
      "source": [
        "# Next-Word Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtNOm_Xyqp0E"
      },
      "source": [
        "## PYTORCH CODE\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "import torch\n",
        "from torch import nn\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grMd5QLrrA0o"
      },
      "source": [
        "sequence = f\"This has been my favorite course so far during my graduate\"\n",
        "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"]\n",
        "# get logits of last hidden state\n",
        "next_token_logits = model(**inputs).logits[:, -1, :]\n",
        "# filter\n",
        "filtered_next_token_logits = top_k_top_p_filtering(next_token_logits, top_k=50, top_p=1.0)\n",
        "# sample\n",
        "probs = nn.functional.softmax(filtered_next_token_logits, dim=-1)\n",
        "next_token = torch.multinomial(probs, num_samples=1)\n",
        "generated = torch.cat([input_ids, next_token], dim=-1)\n",
        "resulting_string = tokenizer.decode(generated.tolist()[0])\n",
        "print(resulting_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtxy8xIVsQMp"
      },
      "source": [
        "# Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9qJxlsirBXs"
      },
      "source": [
        "from transformers import pipeline\n",
        "text_generator = pipeline(\"text-generation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvv3owoVsYIE"
      },
      "source": [
        "print(text_generator(\"This has been my favorite class so far\", max_length=50, do_sample=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHB6mWZwsrz0"
      },
      "source": [
        "# Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJSP8MLsskdL"
      },
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOtHiSP6suXL"
      },
      "source": [
        "ARTICLE = \"\"\" Tesla drivers say they have been locked out of their cars after an outage struck the carmaker's app.\n",
        "Dozens of owners posted on social media about seeing an error message on the mobile app that was preventing them from connecting to their vehicles.\n",
        "Tesla chief executive Elon Musk personally responded to one complaint from a driver in South Korea, saying on Twitter: \"Checking.\"\n",
        "Mr Musk later said the app was coming back online.\n",
        "The Tesla app is used as a key by drivers to unlock and start their cars.\n",
        "Owners posted a multitude of complaints online about not being able to use their vehicles.\n",
        "\"I'm stuck an hour away from home because I normally use my phone to start [my] car,\" one owner tweeted.\n",
        "About 500 users reported an error on the app at around 16:40 ET (21:40 GMT) on Friday, according to the outage tracking site DownDetector. Five hours later, there were just over 60 reports of an error.\n",
        "\"Apologies, we will take measures to ensure this doesn't happen again,\" Mr Musk tweeted.\n",
        "The app is not the only way to access the cars though, Stuart Masson, editor of The Car Expert website, told the BBC.\n",
        "\"\"\"\n",
        "\n",
        "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8lBaWfAuBgj"
      },
      "source": [
        "# Semantic Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrIwe106uJ5c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEgexpkyuQl-"
      },
      "source": [
        "model = SentenceTransformer('stsb-roberta-large')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fxKzOcluUjL"
      },
      "source": [
        "sentence1 = \"Apple's earnings were affected by a recent negative outlook in the market for new headphones\"\n",
        "sentence2 = \"That apple fell on the floor\"\n",
        "sentence3 = \"The market for personal audio devices took a hit last week\"\n",
        "# encode sentences to get their embeddings\n",
        "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
        "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
        "embedding3 = model.encode(sentence3, convert_to_tensor=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXuvjQbCu14y"
      },
      "source": [
        "# compute similarity scores of two embeddings\n",
        "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
        "print(\"Sentence 1:\", sentence1)\n",
        "print(\"Sentence 2:\", sentence2)\n",
        "print(\"Similarity score:\", cosine_scores.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eebiautxu4BB"
      },
      "source": [
        "# compute similarity scores of two embeddings\n",
        "cosine_scores = util.pytorch_cos_sim(embedding1, embedding3)\n",
        "print(\"Sentence 1:\", sentence1)\n",
        "print(\"Sentence 2:\", sentence3)\n",
        "print(\"Similarity score:\", cosine_scores.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGsLq4xu5-R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}